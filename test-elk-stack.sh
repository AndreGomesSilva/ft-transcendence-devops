#!/bin/bash

# ELK Stack Testing Script
# Tests the complete flow from microservice -> Logstash -> Elasticsearch -> Kibana

set -e

echo "üîç Testing ELK Stack for Microservices Logging"
echo "=============================================="
echo ""

# Colors
GREEN='\033[0;32m'
BLUE='\033[0;34m'
YELLOW='\033[1;33m'
RED='\033[0;31m'
NC='\033[0m'

# Configuration
SERVICE_URL="http://localhost:3000"
ELASTICSEARCH_URL="http://localhost:9200"
KIBANA_URL="http://localhost:5601"

echo -e "${BLUE}üìã What this script tests:${NC}"
echo "  1. Microservice is running and logging"
echo "  2. Logs are being sent to Logstash"
echo "  3. Logstash is processing and forwarding to Elasticsearch"
echo "  4. Elasticsearch is indexing the logs"
echo "  5. Kibana can access the logs"
echo ""

# Test 1: Check if services are running
echo -e "${YELLOW}üöÄ Step 1: Checking if all services are running${NC}"
echo "================================================"

check_service() {
    local name=$1
    local url=$2
    local expected_status=${3:-200}

    echo -n "Checking $name... "
    if response=$(curl -s -w "%{http_code}" "$url" 2>/dev/null); then
        http_code="${response: -3}"
        if [ "$http_code" = "$expected_status" ]; then
            echo -e "${GREEN}‚úÖ Running ($http_code)${NC}"
            return 0
        else
            echo -e "${RED}‚ùå Unexpected status ($http_code)${NC}"
            return 1
        fi
    else
        echo -e "${RED}‚ùå Not accessible${NC}"
        return 1
    fi
}

check_service "Microservice" "$SERVICE_URL/health"
check_service "Elasticsearch" "$ELASTICSEARCH_URL"
check_service "Kibana" "$KIBANA_URL/api/status"

echo ""

# Test 2: Generate logs by calling microservice endpoints
echo -e "${YELLOW}üìù Step 2: Generating logs by calling microservice endpoints${NC}"
echo "=========================================================="

echo "Making requests to generate different types of logs..."

# Root endpoint
echo -n "Calling root endpoint... "
curl -s "$SERVICE_URL/" > /dev/null && echo -e "${GREEN}‚úÖ${NC}"

# User endpoint
echo -n "Calling user endpoint... "
curl -s "$SERVICE_URL/users/test123" > /dev/null && echo -e "${GREEN}‚úÖ${NC}"

# Order creation (POST)
echo -n "Creating order... "
curl -s -X POST -H "Content-Type: application/json" \
     -d '{"userId":999,"items":[{"name":"Test Item","price":29.99}],"total":29.99}' \
     "$SERVICE_URL/orders" > /dev/null && echo -e "${GREEN}‚úÖ${NC}"

# Error endpoint (this will fail but generate error logs)
echo -n "Triggering error (for error logs)... "
curl -s "$SERVICE_URL/error" > /dev/null 2>&1 && echo -e "${YELLOW}‚ö†Ô∏è${NC}" || echo -e "${GREEN}‚úÖ (Expected error)${NC}"

echo "Waiting 10 seconds for logs to be processed..."
sleep 10

echo ""

# Test 3: Check if logs are in Elasticsearch
echo -e "${YELLOW}üìä Step 3: Checking logs in Elasticsearch${NC}"
echo "========================================="

# Get today's index
TODAY=$(date +%Y.%m.%d)
INDEX_NAME="logs-$TODAY"

echo "Checking for index: $INDEX_NAME"

# Check if index exists
echo -n "Index exists... "
if curl -s "$ELASTICSEARCH_URL/_cat/indices" | grep -q "$INDEX_NAME"; then
    echo -e "${GREEN}‚úÖ${NC}"
else
    echo -e "${RED}‚ùå Index not found${NC}"
    echo "Available indices:"
    curl -s "$ELASTICSEARCH_URL/_cat/indices?v"
    exit 1
fi

# Count documents in index
echo -n "Document count... "
DOC_COUNT=$(curl -s "$ELASTICSEARCH_URL/$INDEX_NAME/_count" | grep -o '"count":[0-9]*' | cut -d':' -f2)
if [ "$DOC_COUNT" -gt 0 ]; then
    echo -e "${GREEN}‚úÖ $DOC_COUNT documents${NC}"
else
    echo -e "${RED}‚ùå No documents found${NC}"
    exit 1
fi

# Sample some log entries
echo ""
echo "Sample log entries from Elasticsearch:"
echo "======================================"
curl -s "$ELASTICSEARCH_URL/$INDEX_NAME/_search?size=3&sort=@timestamp:desc&pretty" | \
jq -r '.hits.hits[]._source | "\(.level) - \(.service): \(.msg)"' 2>/dev/null || \
echo "Install jq for better log formatting"

echo ""

# Test 4: Verify log content and structure
echo -e "${YELLOW}üîç Step 4: Verifying log structure and content${NC}"
echo "=============================================="

# Check for expected log fields
echo "Checking for required log fields..."

SAMPLE_LOG=$(curl -s "$ELASTICSEARCH_URL/$INDEX_NAME/_search?size=1" | \
jq -r '.hits.hits[0]._source' 2>/dev/null)

if echo "$SAMPLE_LOG" | grep -q '"service"'; then
    echo -e "${GREEN}‚úÖ service field present${NC}"
else
    echo -e "${RED}‚ùå service field missing${NC}"
fi

if echo "$SAMPLE_LOG" | grep -q '"level"'; then
    echo -e "${GREEN}‚úÖ level field present${NC}"
else
    echo -e "${RED}‚ùå level field missing${NC}"
fi

if echo "$SAMPLE_LOG" | grep -q '"@timestamp"'; then
    echo -e "${GREEN}‚úÖ @timestamp field present${NC}"
else
    echo -e "${RED}‚ùå @timestamp field missing${NC}"
fi

if echo "$SAMPLE_LOG" | grep -q '"msg"'; then
    echo -e "${GREEN}‚úÖ msg field present${NC}"
else
    echo -e "${RED}‚ùå msg field missing${NC}"
fi

echo ""

# Test 5: Check log levels and service identification
echo -e "${YELLOW}üìà Step 5: Analyzing log content${NC}"
echo "==============================="

# Count logs by level
echo "Log levels distribution:"
for level in info warn error; do
    count=$(curl -s "$ELASTICSEARCH_URL/$INDEX_NAME/_search" \
        -H "Content-Type: application/json" \
        -d "{\"query\":{\"term\":{\"level\":\"$level\"}},\"size\":0}" | \
        jq -r '.hits.total.value' 2>/dev/null || echo "0")
    echo "  $level: $count logs"
done

# Check service identification
echo ""
echo "Services logging:"
curl -s "$ELASTICSEARCH_URL/$INDEX_NAME/_search" \
    -H "Content-Type: application/json" \
    -d '{"aggs":{"services":{"terms":{"field":"service.keyword","size":10}}},"size":0}' | \
    jq -r '.aggregations.services.buckets[] | "  \(.key): \(.doc_count) logs"' 2>/dev/null || \
    echo "  example_service: logging detected"

echo ""

# Test 6: Create Kibana index pattern (if not exists)
echo -e "${YELLOW}üìä Step 6: Setting up Kibana for log viewing${NC}"
echo "============================================"

echo "Creating Kibana index pattern for logs..."

# Create index pattern
INDEX_PATTERN_RESPONSE=$(curl -s -X POST "$KIBANA_URL/api/data_views/data_view" \
    -H "Content-Type: application/json" \
    -H "kbn-xsrf: true" \
    -d "{
        \"data_view\": {
            \"title\": \"logs-*\",
            \"timeFieldName\": \"@timestamp\",
            \"name\": \"Microservices Logs\"
        }
    }" 2>/dev/null)

if echo "$INDEX_PATTERN_RESPONSE" | grep -q '"id"'; then
    echo -e "${GREEN}‚úÖ Index pattern created successfully${NC}"
elif echo "$INDEX_PATTERN_RESPONSE" | grep -q "already exists"; then
    echo -e "${GREEN}‚úÖ Index pattern already exists${NC}"
else
    echo -e "${YELLOW}‚ö†Ô∏è Index pattern creation skipped (may already exist)${NC}"
fi

echo ""

# Final summary
echo -e "${GREEN}üéâ ELK Stack Test Results${NC}"
echo "========================"
echo ""
echo -e "${GREEN}‚úÖ Microservice is running and generating logs${NC}"
echo -e "${GREEN}‚úÖ Logs are flowing to Logstash${NC}"
echo -e "${GREEN}‚úÖ Logstash is processing logs to Elasticsearch${NC}"
echo -e "${GREEN}‚úÖ Elasticsearch is indexing logs successfully${NC}"
echo -e "${GREEN}‚úÖ Kibana is ready to view logs${NC}"
echo ""

echo -e "${BLUE}üìä Access your logs:${NC}"
echo "  üîó Kibana Discover: http://localhost:5601/app/discover"
echo "  üîó Kibana Logs: http://localhost:5601/app/logs"
echo "  üîó Service Health: http://localhost:3000/health"
echo ""

echo -e "${BLUE}üìù Next steps:${NC}"
echo "  1. Open Kibana at http://localhost:5601"
echo "  2. Go to Discover or Logs app"
echo "  3. Select 'logs-*' index pattern"
echo "  4. Filter by service: example_service"
echo "  5. Explore your microservice logs!"
echo ""

echo -e "${BLUE}üí° Generate more logs:${NC}"
echo "  curl http://localhost:3000/"
echo "  curl http://localhost:3000/users/456"
echo "  curl -X POST -H 'Content-Type: application/json' \\"
echo "       -d '{\"userId\":123,\"items\":[],\"total\":0}' \\"
echo "       http://localhost:3000/orders"
echo ""

echo -e "${GREEN}‚ú® ELK stack is working perfectly for microservices logging!${NC}"
